{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Predicting sentiment from product reviews\n",
    "\n",
    "#Fire up GraphLab Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read some product review data\n",
    "\n",
    "Loading reviews for a set of baby products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = graphlab.SFrame('amazon_baby.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Let's explore this data together\n",
    "\n",
    "Data includes the product name, the review text and the rating of the review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Build the word count vector for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['word_count'] = graphlab.text_analytics.count_words(products['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphlab.canvas.set_target('ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['name'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Examining the reviews for most-sold product:  'Vulli Sophie the Giraffe Teether'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giraffe_reviews = products[products['name'] == 'Vulli Sophie the Giraffe Teether']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(giraffe_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giraffe_reviews['rating'].show(view='Categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Build a sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['rating'].show(view='Categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Define what's a positive and a negative sentiment\n",
    "\n",
    "We will ignore all reviews with rating = 3, since they tend to have a neutral sentiment.  Reviews with a rating of 4 or higher will be considered positive, while the ones with rating of 2 or lower will have a negative sentiment.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore all 3* reviews\n",
    "products = products[products['rating'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive sentiment = 4* or 5* reviews\n",
    "products['sentiment'] = products['rating'] >=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Let's train the sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = products.random_split(.8, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = graphlab.logistic_classifier.create(train_data,\n",
    "                                                     target='sentiment',\n",
    "                                                     features=['word_count'],\n",
    "                                                     validation_set=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Evaluate the sentiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model.evaluate(test_data, metric='roc_curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model.show(view='Evaluation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Applying the learned model to understand sentiment for Giraffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giraffe_reviews['predicted_sentiment'] = sentiment_model.predict(giraffe_reviews, output_type='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giraffe_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Sort the reviews based on the predicted sentiment and explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giraffe_reviews = giraffe_reviews.sort('predicted_sentiment', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giraffe_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Most positive reviews for the giraffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giraffe_reviews[0]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giraffe_reviews[1]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Show most negative reviews for giraffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giraffe_reviews[-1]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giraffe_reviews[-2]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_words = ['awesome', 'great', 'fantastic', 'amazing', 'love', 'horrible', 'bad', 'terrible', 'awful', 'wow', 'hate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use .apply() to build a new feature with the counts for each of the selected_words:** In the notebook above, we created a column ‘word_count’ with the word counts for each review. Our first task is to create a new column in the products SFrame with the counts for each selected_word above, and, in the process, we will see how the method .apply() can be used to create new columns in our data (our features) and how to use a Python function, which is an extremely useful concept to grasp!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first goal is to create a column products[‘awesome’] where each row contains the number of times the word ‘awesome’ showed up in the review for the corresponding product, and 0 if the review didn’t show up. One way to do this is to look at the each row ‘word_count’ column and follow this logic:\n",
    "\n",
    " - If ‘awesome’ shows up in the word counts for a particular product (row of the products SFrame), then we know how often ‘awesome’ appeared in the review,\n",
    " - if ‘awesome’ doesn’t appear in the word counts, then it didn’t appear in the review, and we should set the count for ‘awesome’ to 0 in this review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def awesome_count(sa):\n",
    "    if 'awesome' in sa['word_count']:\n",
    "        sa['word_count']['awesome']\n",
    "    else:\n",
    "        return 0L\n",
    "    \n",
    "# an inline function would have been lambda x['awesome'] = x if 'awseome' in x else: 0L\n",
    "# products['awesome'] = products['word_count'].apply(lambda x = x['awesome'] if 'awseome' in x else: 0L)\n",
    "# or \n",
    "# word = 'awesome'\n",
    "# products[word] = products['word_count'].apply(lambda x = x[word] if word in x else: 0L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['awesome'] = products.apply(awesome_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in selected_words:\n",
    "    products[word] = products['word_count'].apply(lambda x: x[word] if word in x else 0L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Create a new sentiment analysis model using only the selected_words as features**: In the IPython Notebook above, we used word counts for all words as features for our sentiment classifier. Now, you are just going to use the selected_words:\n",
    "\n",
    "Use the same train/test split as in the IPython Notebook from lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = products.random_split(.8, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a logistic regression classifier (use graphlab.logistic_classifier.create) using just the selected_words. Hint: you can use this parameter in the .create() call to specify the features used to be exactly the new columns you just created:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Logistic regression:</pre>"
      ],
      "text/plain": [
       "Logistic regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 133448</pre>"
      ],
      "text/plain": [
       "Number of examples          : 133448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 11</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 11</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 12</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Newton Method</pre>"
      ],
      "text/plain": [
       "Starting Newton Method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Elapsed Time | Training-accuracy | Validation-accuracy |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Elapsed Time | Training-accuracy | Validation-accuracy |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 0.332810     | 0.844299          | 0.842842            |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 0.332810     | 0.844299          | 0.842842            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 0.533693     | 0.844186          | 0.842842            |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 0.533693     | 0.844186          | 0.842842            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 0.767560     | 0.844276          | 0.843142            |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 0.767560     | 0.844276          | 0.843142            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 0.963447     | 0.844269          | 0.843142            |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 0.963447     | 0.844269          | 0.843142            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 6        | 1.219303     | 0.844269          | 0.843142            |</pre>"
      ],
      "text/plain": [
       "| 5         | 6        | 1.219303     | 0.844269          | 0.843142            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 7        | 1.417187     | 0.844269          | 0.843142            |</pre>"
      ],
      "text/plain": [
       "| 6         | 7        | 1.417187     | 0.844269          | 0.843142            |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+--------------+-------------------+---------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+--------------+-------------------+---------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>SUCCESS: Optimal solution found.</pre>"
      ],
      "text/plain": [
       "SUCCESS: Optimal solution found."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_words_model = graphlab.logistic_classifier.create(train_data,\n",
    "                                                     target='sentiment',\n",
    "                                                     features=selected_words,\n",
    "                                                     validation_set=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_words_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7a675cb7dda8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mselected_words_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coefficients'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'selected_words_model' is not defined"
     ]
    }
   ],
   "source": [
    "selected_words_model['coefficients'].sort(['value'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Comparing the accuracy of different sentiment analysis model**: Using the method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - What is the accuracy of the selected_words_model on the test_data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8431419649291376,\n",
       " 'auc': 0.6648096413721418,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      0       |        0        |  234  |\n",
       " |      1       |        0        |  130  |\n",
       " |      0       |        1        |  5094 |\n",
       " |      1       |        1        | 27846 |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns],\n",
       " 'f1_score': 0.914242563530107,\n",
       " 'log_loss': 0.405474711036565,\n",
       " 'precision': 0.8453551912568306,\n",
       " 'recall': 0.9953531598513011,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 100001\n",
       " \n",
       " Data:\n",
       " +-----------+-----+-----+-------+------+\n",
       " | threshold | fpr | tpr |   p   |  n   |\n",
       " +-----------+-----+-----+-------+------+\n",
       " |    0.0    | 1.0 | 1.0 | 27976 | 5328 |\n",
       " |   1e-05   | 1.0 | 1.0 | 27976 | 5328 |\n",
       " |   2e-05   | 1.0 | 1.0 | 27976 | 5328 |\n",
       " |   3e-05   | 1.0 | 1.0 | 27976 | 5328 |\n",
       " |   4e-05   | 1.0 | 1.0 | 27976 | 5328 |\n",
       " |   5e-05   | 1.0 | 1.0 | 27976 | 5328 |\n",
       " |   6e-05   | 1.0 | 1.0 | 27976 | 5328 |\n",
       " |   7e-05   | 1.0 | 1.0 | 27976 | 5328 |\n",
       " |   8e-05   | 1.0 | 1.0 | 27976 | 5328 |\n",
       " |   9e-05   | 1.0 | 1.0 | 27976 | 5328 |\n",
       " +-----------+-----+-----+-------+------+\n",
       " [100001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_words_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - What was the accuracy of the sentiment_model that we learned using all the word counts in the IPython Notebook above from the lectures? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.916256305548883,\n",
       " 'auc': 0.9446492867438502,\n",
       " 'confusion_matrix': Columns:\n",
       " \ttarget_label\tint\n",
       " \tpredicted_label\tint\n",
       " \tcount\tint\n",
       " \n",
       " Rows: 4\n",
       " \n",
       " Data:\n",
       " +--------------+-----------------+-------+\n",
       " | target_label | predicted_label | count |\n",
       " +--------------+-----------------+-------+\n",
       " |      1       |        0        |  1461 |\n",
       " |      0       |        1        |  1328 |\n",
       " |      0       |        0        |  4000 |\n",
       " |      1       |        1        | 26515 |\n",
       " +--------------+-----------------+-------+\n",
       " [4 rows x 3 columns],\n",
       " 'f1_score': 0.9500349343413533,\n",
       " 'log_loss': 0.26106698432421804,\n",
       " 'precision': 0.9523039902309378,\n",
       " 'recall': 0.9477766657134686,\n",
       " 'roc_curve': Columns:\n",
       " \tthreshold\tfloat\n",
       " \tfpr\tfloat\n",
       " \ttpr\tfloat\n",
       " \tp\tint\n",
       " \tn\tint\n",
       " \n",
       " Rows: 100001\n",
       " \n",
       " Data:\n",
       " +-----------+----------------+----------------+-------+------+\n",
       " | threshold |      fpr       |      tpr       |   p   |  n   |\n",
       " +-----------+----------------+----------------+-------+------+\n",
       " |    0.0    |      1.0       |      1.0       | 27976 | 5328 |\n",
       " |   1e-05   | 0.909346846847 | 0.998856162425 | 27976 | 5328 |\n",
       " |   2e-05   | 0.896021021021 | 0.998748927652 | 27976 | 5328 |\n",
       " |   3e-05   | 0.886448948949 | 0.998462968259 | 27976 | 5328 |\n",
       " |   4e-05   | 0.879692192192 | 0.998284243637 | 27976 | 5328 |\n",
       " |   5e-05   | 0.875187687688 | 0.998212753789 | 27976 | 5328 |\n",
       " |   6e-05   | 0.872184684685 | 0.998177008865 | 27976 | 5328 |\n",
       " |   7e-05   | 0.868618618619 | 0.998034029168 | 27976 | 5328 |\n",
       " |   8e-05   | 0.864677177177 | 0.997998284244 | 27976 | 5328 |\n",
       " |   9e-05   | 0.860735735736 | 0.997962539319 | 27976 | 5328 |\n",
       " +-----------+----------------+----------------+-------+------+\n",
       " [100001 rows x 5 columns]\n",
       " Note: Only the head of the SFrame is printed.\n",
       " You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - What is the accuracy of the majority class classifier on this task? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - How do you compare the different learned models with the baseline approach where we are just predicting the majority class? Save these results to answer the quiz at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
